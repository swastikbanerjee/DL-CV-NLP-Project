{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe31568-000d-4ad2-9d88-2ddee18a2622",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import moviepy.editor as mp\n",
    "import speech_recognition as sr\n",
    "import transformers\n",
    "model_name = 'Intel/neural-chat-7b-v3-1'\n",
    "model = transformers.AutoModelForCausalLM.from_pretrained(model_name)\n",
    "tokenizer = transformers.AutoTokenizer.from_pretrained(model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa20a93-7e1e-44d1-bd56-4e4ac4756dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generate_response(system_input, user_input):\n",
    "\n",
    "    # Format the input using the provided template\n",
    "    prompt = f\"### System:\\n{system_input}\\n### User:\\n{user_input}\\n### Assistant:\\n\"\n",
    "\n",
    "    # Tokenize and encode the prompt\n",
    "    inputs = tokenizer.encode(prompt, return_tensors=\"pt\", add_special_tokens=False)\n",
    "\n",
    "    # Generate a response\n",
    "    outputs = model.generate(inputs, max_length=1500, num_return_sequences=1, pad_token_id = tokenizer.eos_token_id)\n",
    "    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "    # Extract only the assistant's response\n",
    "    return response.split(\"### Assistant:\\n\")[-1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed9aa6d9-9edc-493b-830f-a7c29eec0155",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_summary(text):    \n",
    "    system_input = \"You are a summary writing assistant. Your mission is to help users generate concise yet beautiful summaries within 350 words on the input topic.\"\n",
    "    question = f\"Can you generate 350 word summary based on the following topic:{text}\"\n",
    "    response = generate_response(system_input, question)\n",
    "    return (response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f167912-5257-453d-a33c-3721ff30bf5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to convert audio to transcript using SpeechRecognition\n",
    "def convert_audio_to_transcript(audio_path):\n",
    "    recognizer = sr.Recognizer()\n",
    "    with sr.AudioFile(audio_path) as source:\n",
    "        audio_data = recognizer.record(source)\n",
    "        transcript = recognizer.recognize_google(audio_data)\n",
    "    return transcript\n",
    "\n",
    "# Function to convert video to transcript\n",
    "def convert_video_to_transcript(video_path):\n",
    "    # Convert video to audio\n",
    "    audio_path = 'temp_audio.wav'\n",
    "    video = mp.VideoFileClip(video_path)\n",
    "    audio = video.audio\n",
    "    audio.write_audiofile(audio_path)\n",
    "\n",
    "    # Convert audio to transcript\n",
    "    transcript = convert_audio_to_transcript(audio_path)\n",
    "\n",
    "    # Delete temporary audio file\n",
    "    os.remove(audio_path)\n",
    "\n",
    "    return transcript\n",
    "\n",
    "# Main function to handle different types of input\n",
    "def handle_input(input_data):\n",
    "    # Detect input type\n",
    "    if input_data.endswith('.mp4') or input_data.endswith('.avi'):\n",
    "        # Input is a video file\n",
    "        transcript = convert_video_to_transcript(input_data)\n",
    "    elif input_data.endswith('.wav') or input_data.endswith('.mp3'):\n",
    "        # Input is an audio file\n",
    "        transcript = convert_audio_to_transcript(input_data)\n",
    "    elif input_data.endswith('.txt'):\n",
    "        # Input is a text file\n",
    "        with open(input_data, 'r') as file:\n",
    "            transcript = file.read()\n",
    "    else:\n",
    "        # Input is text\n",
    "        transcript = input_data\n",
    "    \n",
    "    return transcript\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adcdc4ee-79e0-4cb9-a053-b9f856530f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # Get input from the user\n",
    "    input_data = input(\"Enter the path to the file or input text: \")\n",
    "    \n",
    "    # Handle input and convert to transcript\n",
    "    transcript = handle_input(input_data)\n",
    "    print(transcript)\n",
    "    \n",
    "    # Generate summary from transcript\n",
    "    summary = generate_summary(transcript)\n",
    "    \n",
    "    # Output summary\n",
    "    print(\"Summary:\", summary)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (IntelÂ® oneAPI 2023.2)",
   "language": "python",
   "name": "c009-intel_distribution_of_python_3_oneapi-beta05-python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
